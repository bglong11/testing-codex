# ESIA Fact Extractor Configuration

# ============================================================================
# LLM PROVIDER SELECTION
# ============================================================================
# Choose which LLM provider to use: ollama, openai, anthropic, gemini
# Default: ollama (free, local)
LLM_PROVIDER=ollama

# ============================================================================
# OLLAMA SETTINGS (Local models - Free)
# ============================================================================
# Recommended models:
#   - mistral:latest (RECOMMENDED - best balance of speed and accuracy)
#   - neural-chat:latest (good instruction following)
#   - dolphin-mixtral:latest (most capable, but slower)
#   - qwen2.5:7b-instruct (large, capable)
OLLAMA_MODEL=mistral:latest
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TEMPERATURE=0.1stat
OLLAMA_MAX_TOKENS=2048

# ============================================================================
# OPENAI SETTINGS (Cloud - Requires API Key)
# ============================================================================
# Get API key from: https://platform.openai.com/
# Cost: ~$0.03-0.30 per 1K tokens (varies by model)
# Set LLM_PROVIDER=openai to use this
OPENAI_API_KEY=your-api-key-here
OPENAI_MODEL=gpt-4
OPENAI_TEMPERATURE=0.1
OPENAI_MAX_TOKENS=2048

# ============================================================================
# ANTHROPIC/CLAUDE SETTINGS (Cloud - Requires API Key)
# ============================================================================
# Get API key from: https://console.anthropic.com/
# Cost: ~$0.008-0.24 per 1K tokens (varies by model)
# Set LLM_PROVIDER=anthropic to use this
ANTHROPIC_API_KEY=your-api-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_TEMPERATURE=0.1
ANTHROPIC_MAX_TOKENS=2048

# ============================================================================
# GOOGLE GEMINI SETTINGS (Cloud - Requires API Key)
# ============================================================================
# Get API key from: https://ai.google.dev/
# Cost: Free tier available, paid for heavy use
# Set LLM_PROVIDER=gemini to use this
GEMINI_API_KEY=your-api-key-here
GEMINI_MODEL=gemini-pro
GEMINI_TEMPERATURE=0.1
GEMINI_MAX_TOKENS=2048

# ============================================================================
# EXTRACTION PARAMETERS
# ============================================================================
# Number of characters per chunk (smaller = more chunks but each processes faster)
CHUNK_SIZE=4000

# Checkpoint frequency (save after N chunks)
CHECKPOINT_FREQUENCY=5

# Conflict detection tolerance (percentage, e.g., 0.02 = 2%)
CONFLICT_TOLERANCE=0.02

# ============================================================================
# FACTSHEET GENERATION PARAMETERS
# ============================================================================
# Skip categorization step (True/False, default False)
# Set True to generate only first 3 CSVs without LLM-based categorization
SKIP_FACTSHEET_GENERATION=False

# Confidence threshold for including facts in factsheet (high/medium/low)
# Default: medium (includes all facts)
# Set to 'high' to only include high-confidence categorizations
FACTSHEET_MIN_CONFIDENCE=medium
